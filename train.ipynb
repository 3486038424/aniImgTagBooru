{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import Resize,ToTensor,Pad\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from DanbooruTagger import DanbooruTagger\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#该cell主要是从当前文件夹下获取图片和标签数据，标签数据是预先定义好的，保存在tokens.txt文件中。也可以传入别的名称调用其他文件作为参数，可以考虑使用TokensSplit.py。\n",
    "#由于数据集的选择，图片位于imagefolder文件夹下，txt文本在txtfolder下，图片和标签通过文件名一一对应，txt中标签使用 ', '分割。自行根据需要修改该部分方法\n",
    "#出于显存和内存的考虑，使用分批次加载，每批次加载1024张到内存，在train函数中判断该批次是否完成训练后在手动重置\n",
    "# 从本地文件夹中加载图片和文本数据\n",
    "image_folder = \"pixiv\\pixiv_top50_deepdan\\pixiv_top50_fin\"\n",
    "txt_folder = \"pixiv\\pixiv_top50_moat\"\n",
    "transf = ToTensor()#这个函数方法是将PIL图像转换为PyTorch张量，并将其归一化到[0, 1]的范围内。\n",
    "\n",
    "class dataLoader:\n",
    "    def __init__(self, image_folder ,txt_folder,labels_file=\"tokens.txt\"):\n",
    "        self.image_folder = image_folder\n",
    "        self.txt_folder = txt_folder\n",
    "        self.image_files = glob.glob(os.path.join(image_folder, \"*.jpg\"))\n",
    "        self.num=0\n",
    "        self.resize=Resize((512,512))#该处定义了图片的尺寸，可以根据需要修改，建议小一些，在6g显卡运存下，256*256 每批可以到16，大约1分钟1024张，如果512*512，每批只能到4张，要10分钟才有1024张\n",
    "        self.all_labels=[]\n",
    "        self.end=False\n",
    "        with open(labels_file, \"r\") as f:\n",
    "            self.all_labels = f.read().strip().split(\"\\n\")\n",
    "    \n",
    "    def numclasses(self):\n",
    "        return len(self.all_labels)\n",
    "    def len(self):\n",
    "        return len(self.image_files)\n",
    "    def isEnd(self):\n",
    "        return self.end\n",
    "    def getXY(self):\n",
    "        X=[]\n",
    "        Y=[]\n",
    "        for nums in range(self.num,self.len() if self.num+1024>self.len() else self.num+1024):\n",
    "            image_file = self.image_files[nums]\n",
    "\n",
    "            #获取图片对应的标签文本\n",
    "            txt_file = os.path.join(txt_folder, os.path.basename(image_file).replace(\".jpg\", \".txt\"))\n",
    "            with open(txt_file, \"r\") as f:\n",
    "                text = f.read().strip().split(\", \")\n",
    "\n",
    "            #读取图片\n",
    "            img = Image.open(image_file)\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')#将图片转换为RGB模式，避免图片为单通道等问题\n",
    "\n",
    "            #填充图片边缘，将短边填充到和长边长度一致\n",
    "            maxlen=img.width if img.width > img.height else img.height\n",
    "            img=Pad([int((maxlen-img.width)/2),int((maxlen-img.height)/2)],fill=(0,0,0),padding_mode='constant')(img)\n",
    "\n",
    "            X.append(self.resize(img))#将图片尺寸调整一致，有利于模型训练，否则会出现图片尺寸不一致导致每次只单张地训练，而且模型学习的深度不够\n",
    "            Y.append(text)\n",
    "\n",
    "        self.num+=1024\n",
    "        self.end=True if self.num>=self.len() else False\n",
    "        \n",
    "        # 将字符串组转换为索引值\n",
    "        label_indices = [[self.all_labels.index(label) if label in self.all_labels else -1 for label in label_list] for label_list in Y]\n",
    "        target = torch.full((len(label_indices), self.numclasses()), 0)\n",
    "\n",
    "        for i, indices in enumerate(label_indices):\n",
    "            if indices != -1:\n",
    "                target[i][indices] = .8 #出于模型的最后一层的激活函数的选择问题，在设置为1的情况下，模型只学到输出值的分布，认为是梯度消失之类的问题\n",
    "        return X,target\n",
    "    \n",
    "loader=dataLoader(image_folder,txt_folder)\n",
    "print(loader.len())\n",
    "print(loader.numclasses())\n",
    "\n",
    "'''激活函数的选择问题'''\n",
    "'''\n",
    "关于模型最后一层的分类层的激活函数，在选择relu下，loss值几乎不收敛，认为模型几乎没学到东西，在选择sigmoid的条件下，模型只学到输出值的分布，任何图像都输出一样的结果\n",
    "softmax不适合多标签分类模型，tanh和sigmoid的问题基本一致\n",
    "最后选择了sigmoid，将结果放在了0.8附近，在这个位置，sigmoid的导数值较大，模型才可以正常训练并且分类\n",
    "我只测试了一次，即正面标签为0.8，反面标签为0，成功实现\n",
    "但是不确定是否为偶然现象，或者别的参数，如0.85和0.05的数据会否更好\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数的定义，传入参数依次为 模型，loss函数，优化器，epoch数，数据加载器，每批数据大小，模型名称\n",
    "# 每训练一轮，保存一次模型\n",
    "# 每训练loader的一个小包数据，输出一次loss，每轮训练输出一次总loss\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs,loader,batch=16,model_name='efftagImg3'):\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        while not loader.isEnd():#该批次的数据是否读完\n",
    "            X,Y=loader.getXY()\n",
    "            run_loss=0.0\n",
    "            i=0\n",
    "\n",
    "            while i+batch < len(X) :  #取一个batch的数据\n",
    "\n",
    "                #将图片拼接成一个完整的inputs的tensor\n",
    "                size=[1,3,X[i].width,X[i].height]\n",
    "                inputs=transf(X[i]).resize_(size)\n",
    "                for w in range(1,batch):\n",
    "                    inputs=torch.cat((inputs,transf(X[i+w]).resize_(size)),0)\n",
    "                inputs=inputs.to(device)\n",
    "\n",
    "                #将标签拼接成一个完整的labels的tensor\n",
    "                labels=torch.Tensor(Y[i:i+batch]).to(device)\n",
    "\n",
    "                outputs = model(inputs)  # 前向传播\n",
    "                outputs=torch.where(torch.isnan(outputs),torch.zeros_like(outputs),outputs)#将非法输出转化为0，早期训练时长出现输出为nan的情况，建议不删\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                run_loss += loss.item()\n",
    "                del inputs\n",
    "                del outputs\n",
    "                i+=batch\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            print(f'Epoch {epoch+1}/{num_epochs} when {loader.num}, Loss: {run_loss/(len(X)/batch)}')\n",
    "            del X\n",
    "            del Y\n",
    "            \n",
    "        loader.num=0\n",
    "        loader.end=False\n",
    "        torch.save(model,model_name+str(epoch)+'.pt')\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/(loader.len()/batch)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#采用迁移训练，模型通过创建是冻结除最后的分类层以外的参数，参照DanbooruTagger.py内的描述\n",
    "model = DanbooruTagger(loader.numclasses())\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10  # 可自行设置训练的轮数\n",
    "criterion =  nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=.02)  \n",
    "train_model(model, criterion, optimizer, 1,loader,64)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "optimizer = optim.Adam(model.parameters(), lr=.002)  \n",
    "train_model(model, criterion, optimizer, num_epochs,loader,16)\n",
    "\n",
    "#torch.save(model,'tagImg3_ls.pt')#最后保存一次模型，有利于之后找到模型，前面的可以选择保存在指定文件夹下，这个放在项目下"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
